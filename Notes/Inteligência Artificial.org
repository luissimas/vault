#+title:Inteligência Artificial

A Inteligência Artificial é o ramo da ciência da computação relacionado com a automação do comportamento inteligente, operando através da criação de modelos para a inteligência e implementando sistemas computacionais baseados nesses modelos.

* Resolução de problemas por Busca
A resolução de problemas por busca consiste em modelar um problema usando uma representação do mundo baseada em *estados* e aplicar um *algoritmo de busca* sobre esses estados para encontrar uma solução para o problema.

** Representação de problemas
Para a resolução de problemas por busca é necessário definir o problema a ser resolvido. Essa definição é composta por dois grupos de elementos essenciais:
- *estados* que representam o mundo
- *ações* que provocam a alteração de um estado para outro

Nesse tipo de resolução assume-se que o ambiente no qual o problema se insere é:
- *observável*: o estado atual é conhecido.
- *discreto*: existe apenas um número finito de ações possíveis em cada estado.
- *conhecido*: o estado resultante de cada ação é conhecido.
- *determinístico*: cada ação leva a apenas um estado.

Para definir um problema são necessários 5 componentes:
- *Estado inicial:* estado a partir do qual a busca se inicia.
- *Ações (ou operadores):* possíveis ações aplicadas a cada estado.
- *Modelo de transição:* descrição do resultado de cada ação com base no estado atual e na ação tomada.
- *Teste final:* condições que determinam se um estado é o objetivo.
- *Custo do caminho:* função que atribui um custo ao caminho, mede a qualidade da solução.

Uma *solução* é uma sequência de ações que vai do estado inicial ao estado objetivo.

** Algoritmos de busca
Com um problema formulado, a solução consiste em realizar uma busca no espaço de estados até encontrar uma sequência de ações que atinjam o estado objetivo. O processo de busca acaba por construir uma *árvore de busca*, cuja raiz é o estado inicial, os nós são os demais estados, as ligações entre nós são as ações e a solução é o caminho da raiz até o nó final (estado objetivo).

No geral os algoritmos de busca possuem a mesma estrutura básica, que consiste em expandir os nós a partir das ações possíveis, gerando novos nós e repetir o processo até que se atinja o nó final. Apesar disso, os algoritmos diferem na *estratégia de busca*, que determina o critério usado para selecionar o próximo nó a ser expandido na árvore de busca.

*** Busca desinformada
As estratégias de busca desinformada não consideram informação adicional sobre o problema além da definição do mesmo. Tendo isso em vista, os algoritmos nessa categoria devem testar todos os nós até encontrar o estado objetivo.

[[../Attachments/IA/breadthanddepth.gif]]

**** Breadth-First (Busca em Largura)
Esse algoritmo consiste em verificar e expandir os nós da árvore de busca nível por nível, dessa forma todos os nós de um determinado nível são expandidos antes de se iniciar a expansão dos nós do próximo nível.

Uma implicação interessante da busca nível a nível é que esse algoritmo sempre encontra o *caminho mais curto* (não necessariamente o caminho ótimo) para a solução.

**** Depth-First (Busca em profundidade)
A busca em profundidade consiste em expandir o nó mais interno até que o nó desse ramo não tenha mais sucessores, após isso retrocede-se ao nó mais profundo e o processo é repetido.

Esse algoritmo *não garante* o caminho mais curto nem a solução ótima, mesmo se as ações tiverem o mesmo custo.

Note que em sua versão mais simples, a busca em profundidade apresenta algumas limitações. Uma delas é a possibilidade de expansão indefinida em um ramo, sem que a solução seja encontrada. Pensando nisso, algumas variações da busca em profundidade foram desenvolvidas na tentativa de remediar algumas dessas limitações fundamentais:

- Busca Limitada: define previamente um nível máximo para a expansão dos nós (note que caso o objetivo esteja em um nível abaixo do limite, ele não será encontrado).
- Busca Limitada Interativa: uma versão melhorada da busca limitada na qual o limite é dinâmico e vai sendo incrementado até que a solução seja atingida.
- Backtracking: apenas o caminho sendo explorado é armazenado, os filhos de cada nó são gerados e explorados um por vez.

**** Busca de Custo Uniforme
Esse algoritmo difere dos demais no sentido de que ele leva em conta o custo dos movimentos de um nó ao outro. A *função de custo* faz parte da definição do problema, e é utilizada por esse algoritmo para decidir qual nó expandir em seguida.

O algoritmo consiste em expandir o nó inicial, manter uma lista dos nós não expandidos ordenada pelo custo dos nós, e então visitar e expandir cada nó de acordo com a ordem dessa lista. Dessa forma os nós menos custosos são sempre verificados primeiro. Quando um nó é expandido, é necessário verificar se ele já havia sido visitado antes (mantendo um alista de nós já expandidos), caso ele já tenha sido visitado, é necessário comparar o custo do caminho atual com o do caminho anterior para aquele nó, e manter apenas o caminho menos custoso. Um ponto importante é que a verificação de nó objetivo só deve ser feita no nó selecionado, e não nos nós expandidos, pois com o primeiro método há a garantia de encontrar sempre o caminho menos custoso para o nó objetivo.

Note que o algoritmo de busca de custo uniforme garante sempre a *solução ótima*, ou seja, a solução de menor custo para o problema.

*** Busca informada
Ao contrário da busca desinformada, a busca informada é uma estratégia de busca que considera *informação específica sobre o problema*, que vão além da definição básica do problema. Nesse tipo de busca, as informações sobre o problema são usadas no momento de selecionar o *próximo nó* a ser expandido. Dessa forma, essa estratégia *não é exaustiva*, ou seja, há mecanismos para evitar que todos os nós devem ser testados para se encontrar o estado objetivo.

As informações específicas ao problema são formuladas como *heurísticas*, que são regras simples utilizadas para avaliar rapidamente um estado. As heurísticas são expressas como funções, de forma que é possível aplicá-las a cada estado.

As heurísticas permitem a aproximação de uma solução, por essa razão são utilizadas principalmente em situações nas quais um problema não possui uma solução exata, ou se essa solução existe mas é muito custosa computacionalmente.

Vale destacar que as buscas com base em heurísticas são *sujeitas a falhas*, no sentido de que a busca pode não encontrar a solução ou encontrar uma solução sub-ótima.

**** Busca pela melhor escolha (best-first)
A busca pela melhor escolha utiliza as heurísticas na forma de uma *função de avaliação* $f(n)$, que aplicada a um estado retorna um valor numérico. A função de avaliação é utilizada para determinar o *quão desejável* é expandir um determinado nó.

De maneira semelhante aos algoritmos de busca desinformada, esse tipo algoritmo mantém listas de nós abertos e fechados, mas armazena também para cada nó expandido o valor da função de avaliação aplicada a ele. Dessa forma, o algoritmo *expande primeiro* os nós com o *melhor valor* da função de avaliação.

A *função de avaliação* pode levar em conta duas métricas:

- A *função de custo* $g(n)$, que representa o custo do caminho da raiz até o nó $n$.
- A *função heurística* $h(n)$, que representa a estimativa de custo do caminho do nó $n$ até o objetivo.

  Vale destacar que o algoritmo de busca pela melhor escolha é na realidade um *modelo* que *engloba diversos outros algoritmos* de busca informada. A ideia geral do algoritmo se mantém, mas as variações de algoritmos surgem nas *diferentes definições* para a *função de avaliação*.

***** Busca Gulosa (Greedy)
Esse algoritmo utiliza como função de avaliação apenas a *função heurística*, ou seja, $f(n) = h(n)$. Dessa forma, os nós considerados mais próximos do objetivo são expandidos primeiro.

Note que não há nenhuma garantia de que esse algoritmo encontra a solução ótima. Entretanto, esse algoritmo é *geralmente* muito *rápido* (pois a função heurística geralmente é de baixo custo computacional). Isso torna o algoritmo de busca gulosa desejável em situações onde o desempenho é preferível ao invés da solução ótima.

***** A*
Utiliza como função de avaliação uma soma da *função de custo* e da *função heurística*, portanto $f(n) = g(n) + h(n)$. Sendo assim, esse algoritmo considera não só a estimativa do custo do caminho do nó $n$ até o objetivo, mas também o custo do caminho percorrido até o nó.

A garantia de que esse algoritmo encontra a *solução ótima* depende da definição da *função heurística*. Se a função heurística nunca superestima o custo de alcançar um objetivo, ou seja, $h(n)$ nunca ultrapassa o custo real do caminho de $n$ até o objetivo, então o algoritmo A* encontra sempre a solução ótima.

**** Busca Local
Os algoritmos de busca local diferem bastante dos outros enunciados até o momento. Essa classe de algoritmos levam em conta *apenas o estado corrente* e se movem apenas para os estados vizinhos deste, *sem levar em conta os caminhos para os estados*. Dessa forma, esse tipo de algoritmo *não mantém* uma lista de *nós abertos e fechados*, sendo necessário armazenar *apenas o estado atual* para então expandi-lo e avaliar os estados possíveis a partir deste.

Esses algoritmos geralmente são *eficientes em termos de memória*, pois não é necessário manter todo o espaço de estados armazenado através de listas de nós. Entretanto, podem muitas vezes levar a *soluções sub-ótimas* ou não levar a solução alguma.

Geralmente os algoritmos de busca local atuam bem em problemas de otimização, nos quais o objetivo é encontrar o *melhor estado* de acordo com uma *função objetivo*.

***** Hill-climbing
O algoritmo hill-climbing é um exemplo claro de algoritmo de busca local. Ele consiste em *expandir um nó* e *avaliar seus descendentes* através de alguma função, que geralmente envolve alguma heurística do problema. Em seguida, o nó com a *melhor avaliação* entre os descendentes é *selecionado* para continuar a busca, e o processo se repete até que o nó selecionado *não gere descendentes com uma avaliação melhor*.

** Algoritmos evolutivos
O algoritmos evolutivos se baseiam na teoria da *seleção natural* de /Charles Darwin/. No início há uma população de indivíduos com diferentes características. Os indivíduos com as melhores característica (mais aptos) são *selecionados* e se reproduzem, gerando uma nova população (geração) de novos indivíduos com *caraterísticas similares*. Dessa forma, a *probabilidade* dos indivíduos *mais aptos reproduzirem suas características* é maior do que a probabilidade dos indivíduos menos aptos fazerem o mesmo.

Nesse tipo de algoritmo, a *solução* de um problema é *representada como um indivíduo*, e uma população consiste em um conjunto de soluções. A ideia então é aplicar uma seleção +natural+ artificial para derivar soluções cada vez melhores.

Um ponto importante para esses algoritmos é a *representação dos indivíduos* e como avaliá-los através de suas características. Essa representação geralmente se baseia na ideia de /genótipos/ e /fenótipos/ da biologia. O *genótipo* é o *conjunto de características* do indivíduo (representado por alguma estrutura de dados), enquanto o *fenótipo* é a forma que o *genótipo* é *aplicado* para *solucionar o problema*. Sendo assim, o fenótipo é o resultado que a solução representada pelo genótipo consegue obter.

Para medir o resultado das soluções, é necessário uma /função de aptidão/ $f: I \to \mathbb{R}$, que *associa indivíduos a um valor de aptidão*.

Os algoritmos evolutivos geralmente seguem o fluxo descrito na imagem, ou seja, a partir de uma *população inicial* são feitas *seleções*, *cruzamentos* e *mutações*, gerando uma nova população, que é selecionada para então repetir o processo até que algum *critério de parada* seja atingido.

Os *critérios de parada* são definidos de acordo com o problema, mas geralmente podem envolver casos como: a convergência da população para uma solução, número máximo de gerações, limite de gerações sem melhora etc.

#+caption: Fluxo de um algoritmo evolutivo
#+attr_org: :width 600
[[file:~/vault/Attachments/IA/evolutionalgorithm.png]]

*** População inicial
Uma *população inicial* deve ser *diversa*, ou seja, deve conter indivíduos com características variadas, para aumentar o espaço de busca da solução e, consequentemente, as chances de encontrar a solução ótima. A população inicial pode ser composta por indivíduos conhecidos previamente para o problema, como soluções em potencial, soluções já conhecidas ou até mesmo soluções aleatórias geradas para o problema.

*** Seleção
Dada uma população, antes de iniciar a combinação e mutação entre os indivíduos, é necessário antes *selecionar os mais aptos* a fim de aumentar as chances de aumento de aptidão entre os novos indivíduos gerados. Dessa forma, a seleção é feita de forma que os *indivíduos mais aptos* possuem *maior probabilidade* de seleção. Diferentes métodos podem ser empregados para a seleção, sendo aqui destacados apenas os mais comuns.

**** Seleção proporcional
Esse método de seleção define que a probabilidade de seleção dos indivíduos é proporcional a sua aptidão. A probabilidade de seleção de um indivíduo $i$ de uma população de tamanho $|P|$ é igual a:

$$
p_i = \frac{f(i)}{\sum_{j=1}^{|P|}f(j)}
$$

**** Seleção determinística
Na seleção determinística os indivíduos são sorteados aleatoriamente e comparados entre si, sendo selecionados apenas o indivíduo com a maior aptidão entre os selecionados. O processo se repete até que todos os indivíduos da população tenham sido testados, tendo sido selecionados apenas aqueles que tiveram a maior aptidão dentre os selecionados em seu turno.

*** Operadores genéticos
A *geração de novos indivíduos* é feita através da aplicação de operadores genéticos. Nesse momento é feita efetivamente uma *busca por novas soluções*, pois novas soluções são geradas a partir das soluções selecionadas. Esses operadores podem ou não utilizar *heurística* para guiar a busca por novas soluções, ou seja, guiar a aplicação dos operadores entre os indivíduos.

**** Cruzamento
No processo de cruzamento, os indivíduos selecionados são cruzados dois a dois, combinando características dos progenitores para gerar novos indivíduos, chamados de descendentes.

A combinação das características dos progenitores pode ser feita de diversas maneiras: trocando características entre os progenitores, utilizando-as como base para gerar características totalmente novas nos descendentes etc.

**** Mutação
A mutação consiste em modificar parte das características de um indivíduo para gerar uma nova característica que não está relacionada a seus progenitores. Esse processo gera soluções inéditas que podem não depender das características anteriores.

Geralmente define-se uma taxa de mutação, que define a probabilidade de uma característica sofrer mutação.

**** Elitismo
O elitismo consiste em selecionar os melhores indivíduos de uma população e incluí-los na próxima geração. Note que os operadores de cruzamento e mutação nem sempre melhoram a população, portanto o processo de elitismo garante que pelo menos alguns indivíduos da próxima geração serão tão bons quanto os melhores indivíduos da geração anterior.

* Representação do Conhecimento e Raciocínio
A *representação do conhecimento* e o *raciocínio* são questões *essenciais* para a inteligência artificial simbólica. A ideia é desenvolver sistemas que *representam conhecimento* e o *utilizam para produzir resultados*. Esses sistemas são chamados de /sistemas baseados em conhecimento (SBC)/. Sistemas baseados em conhecimento devem fornecer meios tanto para adicionar conhecimentos à *base de conhecimento* quanto para obter *inferências* com base nos conhecimentos já existentes.

A *base de conhecimento* consiste em um conjunto de *sentenças*. As sentenças são *declarações* que *expressam conhecimento* sobre o domínio da aplicação. Note que as sentenças devem ser representadas em uma *linguagem sistematizada* e que remova o máximo de ambiguidades, uma linguagem utilizada para esse fim é chamada de *linguagem de representação do conhecimento*.

Dentre as linguagens de representação do conhecimento, a *lógica matemática* se destaca como uma representação formal amplamente usada tanto para *representar o conhecimento* quanto para *modelar o raciocínio* através da *inferência lógica*.

No campo da lógica matemática existem diversas lógicas específicas, com particularidades tanto de representação quanto de inferência. Em geral, alguns *componentes e propriedades são necessários* à qualquer lógica *para representar conhecimento e raciocinar* com base no mesmo:

- O conceito de *verdade* é essencial para avaliar a veracidade das sentenças e a partir disso construir o conhecimento.
- Um *mundo possível* é um ambiente real do qual se extrai ou ao qual se aplica o conhecimento.
- Um *modelo* é a especificação formal de um mundo possível. Um modelo *define o valor-verdade de uma sentença*. Dizemos que um modelo *satisfaz* uma sentença se essa sentença for *verdadeira* para o modelo.
- A *consequência lógica* define as relações entre sentenças, compondo a base da inferência lógica.
- A *inferência lógica* consiste na verificação da consequência lógica entre sentenças, permitindo verificar se uma sentença decorre de um conjunto de sentenças já conhecidas.
- A *consistência* é uma propriedade de algoritmos de inferência que derivam apenas sentenças permitidas dentro da sintaxe e semântica da lógica.
- A *completeza* de um algoritmo de inferência é uma propriedade que indica se o dado algoritmo é capaz de derivar qualquer sentença possível dentro da lógica em questão.

* Aprendizado de Máquina
O aprendizado de máquina é a área da computação que estuda técnicas que permitem que sistemas computacionais "aprendam" a realizar tarefas com base em dados prévios sobre o problema, sem serem explicitamente programados para a tarefa.

A grande maioria das estratégias de aprendizado de máquina realizam o chamado *aprendizado indutivo*, que se baseia no processo de *indução* para derivar conclusões genéricas sobre um conjunto particular de conhecimento e observações empíricas. A ideia básica é apresentar uma série de exemplos a um algoritmo, que fará o processo de indução para, a partir os exemplos e dados de situações específicas, obter *hipóteses* capazes de inferir conclusões sobre novos dados.

Todo algoritmo de aprendizado de máquina possui algum *viés*, isto é, a tendência a privilegiar uma hipótese ou conjunto de hipóteses no processo de generalização. O viés pode ser resultado tanto da *representação* das hipóteses pelo algoritmo, que define e restringe o espaço de hipóteses possíveis, quanto da própria busca e os métodos utilizados para considerar uma hipótese melhor do que a outra. Vale destacar que o viés é essencial para restringir o espaço de hipóteses possíveis e de fato encontrar uma generalização. Sem viés não seria possível obter nenhuma generalização a partir de dados.

É necessário notar a relação da variância e do viés com relação à capacidade de generalização de um algoritmo. Caso o viés seja muito fraco, há a possibilidade de *underfitting*, ou seja, o modelo gerado pelo algoritmo é tão genérico que é incapaz de fazer qualquer inferência, mesmo com os dados usados para o treinamento. O caso contrário seria o de um viés muito forte, situação na qual é possível observar o *overfitting*, ou seja, o modelo se adéqua tanto aos dados de treinamento que se especializa nos dados fornecidos para o treino, sendo incapaz de generalizar e inferir conclusões sobre novos conjuntos de dados .

#+caption: Visualização de situações de underfitting e overfitting
#+attr_org: :width 700
[[file:~/dox/vault/Attachments/IA/overfittingunderfitting.png]]

Os algoritmos de aprendizado de máquina podem ser aplicados na resolução dos mais diversos problemas. Por essa razão há uma grande *variedade de algoritmos* especializados em classes específicas de problemas. Geralmente a *classificação* dos algoritmos é dada de acordo com o *tipo de tarefa* a ser realizada.

#+caption: Classificações de aprendizado de máquina
#+attr_org: :width 700
[[file:~/dox/vault/Attachments/IA/mltypes.png]]

** Aprendizado supervisionado
O aprendizado supervisionado é um paradigma de aprendizado aplicado principalmente em problemas de classificação e regressão. Em ambos os tipos de problemas são fornecidos conjuntos de dados de treinamento com diversos atributos de entrada e um atributo de saída. A ideia é que o algoritmo gere um modelo capaz de, dado um novo conjunto de atributos de entrada diferente daqueles utilizados para o treinamento, produza o atributo de saída esperado. O conceito de *aproximação de funções* é muito relacionado a esse paradigma de aprendizado.

Problemas de *classificação* geralmente envolvem a associação de atributos de entrada a um atributo de saída discreto (geralmente uma classe ou *categoria*). Problemas desse tipo envolvem a identificação de fraudes, classificação de imagem, diagnósticos etc. Problemas de *regressão* partem do mesmo princípio, entretanto a ideia é associar atributos de entrada a um atributo de saída contínuo (um valor numérico). Problemas desse tipo envolvem predições de mercado financeiro, estimativa de funções etc.

O termo "supervisionado" se origina do pressuposto que há algum *agente externo* que conhece a *saída esperada* para cada exemplo no conjunto de dados de treinamento, portanto é possível avaliar a capacidade de predição dos modelos gerados.

** Aprendizado não supervisionado
O paradigma de aprendizado supervisionado é utilizado principalmente em problemas de agrupamento, associação e sumarização de dados. Esses tipos de algoritmos não buscam inferir conclusões a partir de novos conjuntos de dados, mas sim *descrever*, *aprofundar* e obter informações sobre um *conjunto de dados específico*.

Problemas comuns que utilizam aprendizado não supervisionado são problemas de *associação e visualização de dados* em um grupo. Esses algoritmos permitem, por exemplo, fornecer informações sobre quais tipos de produtos são frequentemente comprados juntos, ou quais perfis de consumidor são mais propensos a comprarem determinada categoria de produto.

O termo "não supervisionado" deriva do fato de que não há algum agente externo, nem há uma saída esperada e conhecida para um determinado conjunto de dados de treinamento. A ideia desse tipo de algoritmo é explorar e derivar informações úteis sobre um conjunto de dados, não generalizar hipóteses para predições com novos dados.

** Aprendizado por reforço
O aprendizado por reforço se baseia no *feedback* positivo ou negativo ao modelo dependendo da ação escolhida pelo mesmo. A ideia é que o modelo aprenda através das próprias experiências positivas e negativas.

Problemas comuns nessa área geralmente envolvem tomada de decisões, jogos, navegação, etc.
