#+title:Álgebra Linear

* Espaços Vetoriais
  Dado um conjunto $V$ não-vazio, se em $V$ estiverem definidas: uma operação de adição tal que, para todo par de elementos  $x, y \in V$, associa-se um terceiro elemento $x + y \in V$, ou seja:

  $$+ : V \times V \to V$$

  e uma operação de multiplicação por escalar tal que, para cada elemento $\alpha \in \mathbb{R}$ e para cada elemento $x \in V$, associa-se um elemento $\alpha x \in V$, ou seja:

  $$\cdot : \mathbb{R} \times V \to V$$

  O conjunto $V$ é um *espaço vetorial real* em relação a essas operações se, para quaisquer $\alpha, \beta \in \mathbb{R}$ e $u, v, w \in V$, as seguintes *propriedades* forem satisfeitas:

  A_1) *(Associatividade)* $(x + y) + z = x + (y + z)$
  A_2) *(Comutatividade)* $x + y = x + y$
  A_3) *(Elemento neutro)* $\exists 0 \in V \mid u + 0 = 0 + u = u$
  A_4) *(Elemento simétrico)* $\forall u, \exists -u \mid x + (-x) = 0$
  M_1) *(Distributividade)* $\alpha (u + v) = \alpha u + \alpha v$
  M_2) *(Distributividade)* $(\alpha + \beta)u = \alpha u + \beta u$
  M_3) *(Associatividade)* $(\alpha \beta)u = \alpha (\beta u)$
  M_4) *(Elemento neutro)* $1 \cdot u = u$

  Os conjuntos $\mathbb{R}, \mathbb{R}^{2}, \mathbb{R}^3, \dots , \mathbb{R}^n$ com suas definições tradicionais de adição e multiplicação são exemplos de espaços vetoriais.

** Subespaço Vetorial
Subespaços vetoriais são *subconjuntos* de espaços vetoriais. Cada subespaço vetorial deve estar associado a um espaço vetorial do qual ele é um subconjunto.

Seja $V$ um espaço vetorial e seja $W$ um subconjunto de $V$ tal que $W \neq \emptyset$. Dizemos que $W$ é um /subespaço vetorial/ de $V$ se as seguintes condições forem satisfeitas:

a) $\forall u, v \in W \to u + v \in W$
b) $\forall \alpha \in \mathbb{R}, \forall u \in W \to \alpha u \in W$
c) $0 \in W$

Note que a condição /c)/ deriva da condição /b)/, pois ao multiplicar um elemento pelo escalar 0 deve-se poder obter o elemento nulo do conjunto $W$. Veja também que, por definição, o espaço vetorial $V$ é um subespaço vetorial dele mesmo.

Sabendo disso, infere-se que todo espaço vetorial admite ao menos dois subespaços vetoriais, o conjunto formado apenas pelo vetor nulo e o próprio conjunto. Esses dois subespaços são chamados de *subespaços triviais*, enquanto todos os outros subespaços de um espaço vetorial são chamados de *subespaços próprios*.

Os subespaços vetoriais possuem propriedades interessantes que garantem duas operações: a intersecção e a soma de subespaços vetoriais.

Sejam $W_1$ e $W_2$ subespaços vetoriais de um espaço vetorial $V$, a *intersecção* $W_1 \cap W_2$ destes subespaços *é também um subespaço vetorial* de $V$.

Sejam $W_1$ e $W_2$ subespaços vetoriais de um espaço vetorial $V$, a *soma* destes subespaços, dada por:

$$ W_1 + W_2 = \{w \in V; w = u + v, u \in W_1, v \in W_2\}$$

*é também um subespaço vetorial* de $V$.

** Combinação Linear
A combinação linear é uma característica dos espaços vetoriais que permite a obtenção de novos vetores a partir de vetores conhecidos.

Seja $V$ um espaço vetorial real. Dados $n$ vetores $v_1, v_2, \dots, v_n \in V$ e $n$ números reais $\alpha_1, \alpha_2, \dots, \alpha_n \in \mathbb{R}$, o vetor

$$u = \alpha_1 u_1 + \alpha_2 + u_2 + \dots + \alpha_n u_n = \sum_{i=1}^{n} a_i u_i$$

é um elemento de $V$ e é chamado de *combinação linear* de $u_1, u_2, \dots, u_n$. Os escalares $a_i$ são chamados de *coeficientes* da combinação linear.

** Subespaço gerado
Seja $V$ um espaço vetorial e $S = \{u_1, u_2, \dots, u_n\}$ um subconjunto de $V$. O subconjunto de $V$ formado por *todas as combinações lineares* de elementos de $S$, ou seja:

$$[S] = \{a_1 u_1 + a_2 u_2 + \dots + a_n u_n \mid a_i \in \mathbb{R}, \forall i\}$$

é chamado de *espaço vetorial gerado* por $S$. Os vetores $u_1, u_2, \dots, u_n$ são chamados *geradores* de $[S]$. Note que $[S]$ é um subespaço vetorial de $V$.

** Dependência Linear
Seja $V$ um espaço vetorial e $u_1, u_2, \dots, u_n \in V$. O conjunto $\{u_1, u_2, \dots, u_n\}$ é dito *linearmente independente (L.I.)* se e somente se a equação

$$
a_1 u_1, a_2 u_2, \dots, a_n u_n = 0
$$

tiver apenas a solução $a_1 = a_2 = \dots = a_n = 0$, chamada de /solução trivial/. Caso a equação seja satisfeita para algum $a_i \neq 0$, o conjunto é dito *linearmente dependente (L.D.)*.

Note que o subconjunto unitário $\{0\}$ de um espaço vetorial $V$ é *L.D.*, pois para qualquer $a \in \mathbb{R}$ a equação é satisfeita. De forma análoga, um subconjunto unitário $\{v\}, v \neq 0$ de um espaço vetorial $V$ é *L.I.*, pois a equação só é satisfeita para $a=0$.

Para verificar se um conjunto de vetores é *L.I.* ou *L.D.* devemos, sempre, resolver um *sistema linear homogêneo*. Nesse caso os vetores são *L.I.* se a única solução do sistema linear é a solução trivial, e os vetores são *L.D.* se o sistema admite infinitas soluções. Uma forma alternativa à resolução dos sistemas lineares é calcular os determinantes da matriz dos coeficientes. Seja $A$ a matriz dos coeficientes do sistema linear, se $det(A) = 0$, então o sistema admite infinitas soluções, logo os vetores são *L.D.*; caso contrário, ou seja, se $det(A) \neq 0$, então o sistema admite apenas a solução trivial, logo os vetores são *L.I.*.

O teorema enunciado a seguir relaciona a *dependência* com *combinação* linear:

O conjunto $\{u_1, u_2, \dots, u_n\}$ é *linearmente dependente (L.D.)* se e somente se um dos vetores $u_i$ for *combinação linear* dos outros.
