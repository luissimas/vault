#+title:Organização e Recuperação da Informação

Organização e Recuperação da Informação, como o nome já diz, é a área que estuda como organizar e recuperar informações armazenadas na memória secundária de sistemas computacionais. Essa área fornece a base teórica e prática não só para a manipulação de arquivos em geral, mas também para a implementação de bancos de dados e quaisquer programas que acessem a memória secundária.

* Processamento sequencial e ordenação externa
A ordenação externa consiste em classificar e ordenar por algum critério os registros armazenados em um arquivo. Naturalmente, o *acesso a disco* é algo muito mais *custoso* do que o acesso a dados na memória principal, portanto o principal objetivo dos algoritmos que lidam com processamento e ordenação de arquivos é fazer o mínimo de *acessos a disco possíveis*.

A primeira técnica usada para reduzir o número de acessos é o *acesso sequencial* aos registros. Quando o processamento de um arquivo é sequencial, isto é, os registros são acessados em ordem e em sequência, o tempo de acesso é otimizado, pois reduz-se o tempo gasto com o /seeking/ (movimento da cabeça de leitura do disco), já que a cabeça é posicionada apenas uma vez, e então os dados podem ser lidos com a rotação do disco, sem necessidade de um novo /seeking/.

Quando dois ou mais arquivos são processados ao mesmo tempo, cada um de forma sequencial, temos o chamado *processamento cossequencial*.

Nem sempre a ordenação externa é necessária, e em geral o melhor a se fazer é evitá-la, visto que é muito mais eficiente carregar todos os registros na memória principal, utilizar um algoritmo de ordenação, e então escrever os dados no arquivo. Entretanto, nem *sempre é possível carregar todos os dados na memória principal*, e é justamente nesses casos que a ordenação externa se faz necessária.

Visando a eficiência, um algoritmo de ordenação externa deve sempre buscar minimizar o número de acessos a disco, isso pode ser feito com duas ações principais:

- Ler cada registro o menor número de vezes possível.
- Processar o arquivo sequencialmente, do início ao fim.

** Ordenação por intercalação balanceada
O principal método de *ordenação externa* é a ordenação por intercalação balanceada, que utiliza tanto da memória principal quanto a secundária para ordenar os dados de um arquivo.

Esse algoritmo consiste em ler o arquivo sequencialmente, carregando o máximo de registros possíveis na memória, ordenando-os na memória principal e então escrevendo-os em arquivos intermediários, formando *blocos* de registros ordenados nos arquivos. Após isso, os arquivos intermediários são lidos cossequencialmente e é feito o *merge dos blocos* dos arquivos sucessivamente em mais arquivos intermediários, até que se obtenha um *único bloco ordenado* no arquivo final. Com esse método de leitura, é possível ler apenas um registro de cada bloco intermediário por vez, tornando o número de registros do arquivo inicial irrelevante para o processamento.

Dado um arquivo contento $n$ registros, e uma memória principal com capacidade para até $m$ registros. A passada inicial sobre o arquivo produz $\frac{n}{m}$ blocos ordenados. Seja $P$ uma função tal que $P(n)$ é o número de passadas para a fase de intercalação dos blocos ordenados, e seja $f$ o número de arquivos intermediários utilizados em cada passada, para uma intercalação com $f$ caminhos o número de passadas é dado por

$$ P(n) = \log_f \frac{n}{m}$$

Considerando a primeira passada pelo arquivo para formar os primeiros blocos ordenados, o número total de passadas pelo arquivo é dado por $P(n) + 1$.

* Armazenamento e organização de arquivos
Os dispositivos de armazenamento secundário são geralmente *dispositivos de blocos*, isto é, a unidade mínima de armazenamento não são bytes, e sim *grupos de bytes*.

Além da formatação /física do disco/ em setores, trilhas e cilindros, existe também uma /formatação lógica/, feita através de um *sistema de arquivos*. Um sistema de arquivos divide o disco em *regiões endereçáveis* para o sistema operacional e fornece a infraestrutura básica de manipulação de arquivos em memória secundária, oferecendo operações primitivas básicas para a manipulação desses arquivos.

No disco, um arquivo nada mais é do que uma *sequência de bytes* armazenados de forma contínua. Entretanto, para o sistema de arquivos um arquivo é na realidade um conjunto de *páginas de disco*. As páginas de disco são um *conjunto de setores* no disco, e são a unidade de transferência entre disco e memória principal pelo sistema operacional, ou seja, quando uma leitura ou escrita é solicitada ao sistema operacional, uma página inteira é lida ou escrita, independente do tamanho do arquivo de leitura ou da quantidade de dados a ser escrita. Além disso, o sistema operacional também fornece a abstração de *posição corrente*. A posição corrente no arquivo é uma abstração que permite especificar a partir de qual byte um arquivo deve ser lido ou escrito.

#+caption: Páginas de disco.
#+attr_org: :width 500
[[../Attachments/ORI/paginasdisco.png]]

O fato dos arquivos serem gravados ao longo de blocos de disco gera um efeito colateral: a *fragmentação interna*. A fragmentação ocorre quando um arquivo não usa seu último bloco completamente, desperdiçando o espaço do resto do bloco. Como os blocos são as unidades endereçáveis do disco, *um bloco deve conter apenas um arquivo*, portanto o espaço restante de um bloco que não está sendo completamente utilizado não pode ser reaproveitada para nenhum arquivo.

Um arquivo é apenas uma *sequência de bytes* escritos no disco, e uma sequência de bytes por si só *não tem valor ou informação alguma*, pois não há *contexto* e nem *estrutura* para que os dados armazenados tenham algum significado. Portanto, além de uma forma de armazenamento e endereçamento, é necessário estabelecer um método para *impor estrutura* aos dados armazenados, organizar os arquivos. A organização de arquivos é feita em um *nível conceitual* através de campos e registros.

** Campos
Os campos são a menor unidade lógica de armazenamento, geralmente utilizados para armazenar um *dado singular*. Cada campo ocupa um tamanho no arquivo final, e esse tamanho pode ser *fixo* ou *variável*.

Campos de *tamanho fixo* têm seu tamanho definido previamente, independente do dado a ser armazenado. Esse tipo de campo torna a *busca simples*, pois sabendo previamente o tamanho de todos os campos é fácil encontrar a posição deles nos arquivos. Entretanto, esse método pode gerar um grande *desperdício de armazenamento*, pois o espaço alocado nem sempre é usado por completo. Esse problema se agrava ainda mais quando os dados a serem armazenados têm uma alta variação de tamanho.

Para campos de *tamanho variável* existem algumas alternativas de implementação: O primeiro método de implementação consiste em *armazenar o tamanho* ocupado por cada campo *antes do campo* em si. Dessa forma, pode-se ler o tamanho do primeiro campo e então saber qual a posição do segundo, e assim sucessivamente. É possível também *separar os campos por delimitadores*, caracteres especiais que não fazem parte dos dados representados. Esses separadores são *inseridos ao final de cada campo*. Dessa forma, é possível saber onde um campo se inicia e termina com base nos delimitadores ao seu redor. Outra alternativa é o uso de *tags*, criando uma expressão de chave-valor no campo. Nessa forma de implementação uma *tag* é colocada *antes do campo*, *definindo a semântica* para o dado. Esse método geralmente é utilizado em conjunto com outros, como os delimitadores. Em geral, os campos de tamanho variável são mais *eficientes em termos de armazenamento*, porém *aumentam a complexidade das buscas* no arquivo.

** Registros
Os registros são agrupamentos de campos, que definem uma informação mais complexa com vários atributos, ou uma *entidade*. Da mesma forma que é necessário organizar os campos dentro de registros, é necessário organizar os registros dentro de arquivos. Existem várias maneiras de organizar os registros em um arquivo, sendo algumas delas análogas à organização de campos, mas com algumas peculiaridades.

A primeira alternativa é manter registros de *tamanho fixo*, isso pode ser atingido mantendo campos de tamanho fixo ou variável. Se os campos de um registro possuem tamanho fixo, então esse registro obrigatoriamente tem tamanho fixo. Entretanto, se um registro tem tamanho fixo, isso não implica nem em um número fixo de campos e nem em um tamanho fixo para esses campos.

É possível também manter registros de *tamanho variável* com um *número fixo de campos*. Isso cria a necessidade de utilização de algum método de separação dos campos, como delimitadores. Nesse tipo de implementação o tamanho do registro em bytes varia, mas como seu número de campos é sempre o mesmo, é possível distinguir os registros através dos campos.

Outra alternativa é utilizar um *indicador de tamanho* para os registros. Dessa forma, no início de cada registro há um indicador que fornece o tamanho do registro. Note que nessa implementação é necessário que os campos sejam separados internamente por delimitadores.

Existe ainda uma forma de manter registros de tamanho variável sem a necessidade de indicadores. Esse método consiste em manter um *índice de endereçamento* em um arquivo secundário, que armazena o endereço do primeiro byte de cada registro no arquivo principal. Dessa forma, é possível acessar cada registro utilizando os endereços e calcular seu tamanho a partir do próximo endereço. Note que essa implementação introduz a preocupação de manter consistência entre os dois arquivos, quaisquer modificações no arquivo principal devem ser refletidas no arquivo de índice.

É possível ainda *separar os registros com delimitadores*, de maneira análoga à separação de campos. Note que para combinar os delimitadores de campos e de registros esses delimitadores devem ser caracteres diferentes.

** Formas de acesso
Existem essencialmente duas maneiras de se acessar arquivos armazenados em memória secundária:

- O *busca sequencial* lê o arquivo registro a registro.
- O *acesso direto* indica a posição do arquivo a ser lida, resultando em uma operação de /seek/, movendo a cabeça do disco até o registro desejado, que então é lido diretamente.

Se tratando de acesso a disco, o desempenho é medido em termos do *número de acesso a disco*. Nesse contexto, o custo dos tipos de acesso no pior caso é dado por:

- *Busca sequencial*: custo linear, proporcional ao número de registros ou de páginas de disco que contém os registros do arquivo.
- *Acesso direto*: custo constante, pois um único acesso é capaz de recuperar o registro, independentemente do tamanho do arquivo.

A busca sequencial pode ser muito *ineficiente*, principalmente quando deseja-se ler apenas um registro de um arquivo grande. Entretanto, ela tem uma *implementação simples* e pode ser aplicada a diversos tipos de arquivos. Em contrapartida, o acesso direto se mostra muito eficiente principalmente nos casos onde é necessário ler apenas um registro ou um conjunto de registros armazenados na mesma página de disco.

A implementação de acesso direto não é tão simples quando a de busca direta. Apesar disso, duas técnicas são comumente utilizadas quando é necessário implementar acesso direto:

- O *RRN (relative record number)* é usado quando os registros são de *tamanho fixo*. A ideia é que com registros de tamanho fixo é possível *calcular a posição de início* do registro *com base na posição relativa* do registro dentro do arquivo.
- Um *arquivo de índice* é utilizado tanto para registros de tamanho fixo quanto para os de tamanho variável. Nesse tipo de implementação é necessário manter um arquivo secundário com as posições de início de cada registro do arquivo principal.

** Remoção e compactação
Ao remover registros de um arquivo, é necessário reorganizar o aquivo para que o espaço ocupado seja efetivamente reduzido.

Em geral, primeiramente é feita uma *remoção lógica* do registro, que consiste em marcá-lo como *inválido*, sem efetivamente removê-lo do arquivo. Após a remoção lógica, ocorre a *remoção física*, que de fato *recupera o espaço* ocupado pelo registro removido no arquivo.

Em geral, existem duas abordagens para a recuperação de espaço de registros removidos em arquivos:

*** Recuperação estática
A recuperação estática consiste em *reconstruir o arquivo*, eliminando todos os registros marcados como inválidos de uma só vez. O processo de remoção dos registros marcados como inválidos é chamado de *compactação*. Note que a compactação é feita de maneira *esporádica*, ou seja, define-se um intervalo de tempo para que a compactação seja realizada no arquivo.

*** Recuperação dinâmica
Na recuperação dinâmica é possível *reutilizar o espaço* ocupado pelos registros marcados como inválidos para realizar novas inserções, sem a necessidade de aguardar a compactação.

Para implementar essa estratégia em arquivos de *registros de tamanho fixo*, implementa-se uma *pilha* através de *lista encadeada*, onde cada nó é um registro marcado para remoção, no próprio arquivo. Como os registros são de tamanho fixo, é possível endereçá-los através do *RRN*. Dessa forma, um *registro removido contém* o *RRN do próximo registro removido* na pilha, e o *arquivo armazena um ponteiro* com o valor do RRN do registro no *topo da pilha*. Nessa estratégia as inserções ocorrem sempre no topo da pilha, ou seja, os primeiros espaços a serem reaproveitados são os dos registros removidos mais recentemente.

Quando os registros são de *tamanho variável*, não basta apenas manter uma lista encadeada e manipulá-la como uma pilha, pois agora é necessário analisar os tamanhos dos registros disponíveis para serem reutilizados. Portanto, a implementação dessa estratégia usa também uma *lista encadeada*, onde cada nó é contém o *tamanho do registro* marcado para remoção e um *ponteiro* para o próximo registro marcado para remoção. Nesse caso em que os registros são de tamanho variável, os ponteiros são na realidade o *byte offset* para o início do registro com relação ao início do arquivo. Dessa forma, quando uma inserção é realizada, é necessário *verificar o tamanho* de todos os registros disponíveis para substituição na lista, e então inserir o novo registro em um espaço que comporte seu tamanho.

A recuperação dinâmica em registros de *tamanho variável* gera um problema: como os registros são de tamanho diferente, é comum que "sobre" espaço após a reutilização de um espaço disponível. Esse fenômeno é chamado de *fragmentação*. Para minimizar esse problema, deve ser adotada alguma *estratégia de alocação* para escolher em qual dos espaços disponíveis no arquivo um novo registro deve ser inserido, levando em conta o tamanho do novo registro. Em geral, duas estratégias são utilizadas:

- A alocação *best-fit* prioriza o *menor espaço* disponível que seja capaz de conter o novo registro. Essa estratégia causa *fragmentação externa*, ou seja, com o tempo acabam sobrando muitos espaços pequenos, pequenos demais para serem preenchidos por outro registro.
- A alocação *worst-fit* prioriza o *maior espaço* disponível, diminuindo assim a fragmentação externa. Dessa forma, os espaços que sobram em geral são maiores do que os na estratégia best-fit.

* Indexação
É possível buscar por registros diretamente no arquivo que contém aquele registro. Entretanto, dada a organização potencialmente complexa dos registros em um arquivo, essa busca pode se tornar ineficiente pela falta de bons métodos de busca a serem aplicados diretamente nos arquivos.

Uma solução que permite acelerar o processo de busca é a criação de um *índice* para o arquivo principal. Um índice é uma *estrutura auxiliar* que tem por objetivo *melhorar a eficiência da busca* por registros em um arquivo.

Geralmente um índice é implementado como um *arquivo separado* composto por *registros de tamanho fixo*, que por sua vez são compostos por *campos de tamanho fixo*. Essa escolha de organização dos arquivos de índices torna seu *acesso muito simples*, e como geralmente não há grande variabilidade nos dados armazenados, o desperdício de espaço é justificável em virtude da melhora na eficiência da busca.

Cada registro de um índice armazena dois dados:

- Uma *chave de busca* que permite identificar o registro buscado no arquivo principal. Essa chave pode ser tanto um campo quanto uma combinação de campos do arquivo principal.
- Um *campo de referência* que indica a posição do registro no arquivo através do /RRN/ ou do /byte offset/.

Além disso, os registros dos índices geralmente são *ordenados* de acordo com a chave de busca. Dessa forma, é possível aplicar algoritmos de busca mais eficientes, como a *busca binária* para encontrar rapidamente a posição do campo no arquivo principal.

** Tipos de índices
Em geral, existem duas classificações para índices de acordo com a *ordem* de seus registros:

- Em um índice *agrupado* a ordem dos registros é a mesma ou muito próxima à ordem dos registros no arquivo principal.
- Em um índice *não agrupado* a ordem dos registros não coincide com a ordem dos registos no arquivo principal.

Além disso, os arquivos de índices podem ser classificados de acordo com a *quantidade de entradas* de índice em relação à quantidade de registros no arquivo principal:

- Um índice *denso* armazena um registro para *cada registro* no arquivo principal. Dessa forma, é possível *acessar diretamente* o registro no arquivo principal. Note que esse tipo de índice ocupa um espaço diretamente proporcional ao tamanho do arquivo principal.
- Um índice *esparso* armazena um registro para *cada página* no arquivo principal. Assim, é possível acessar apenas a página do registro, sendo necessário finalizar a busca pela chave desejada no próprio arquivo. Apesar, de oferecer uma busca *menos eficiente* do que um *índice denso*, um índice esparso *ocupa menos espaço*. Vale notar também que esse tipo de índice necessariamente deve ser *agrupado*, pois a ordem dos registros é fundamental para localizar sua página.

** Manutenção e organização
Com a criação de um índice, é introduzida uma dificuldade: sua *manutenção*. Para que o índice continue sendo eficiente, as *mudanças no arquivo principal* devem ser *refletidas* também no *arquivo de índice*. Isso inclui as operações de remoção, inserção, atualização entre outras.

Quando o arquivo de índice pode ser carregado diretamente na memória, pode-se utilizar a estratégia de organização *linear*, na qual o índice é *carregado na memória principal* como um array e são empregados algoritmos de busca para encontrar os registros desejados. Entretanto, nem sempre é possível carregar o arquivo de índice inteiro na memória. Nesses casos, é mais eficiente utilizar outras formas de organização, como *hashing* ou *árvores B*, com o objetivo de minimizar os acessos a disco e, consequentemente, tornar a busca mais eficiente.

** Índices secundários
Um *índice secundário* é definido com base em uma *chave secundária*, que identifica *um ou mais registros* no arquivo principal. Podem ser definidos diversos índices secundários para um arquivo, permitindo que a busca seja otimizada para diversas chaves secundárias.

Em geral, existem dois tipos de índices secundários:

- Índices *fracamente ligados* relacionam a chave secundária à *chave primária* do registro no índice principal. Esse tipo de índice *reduz a complexidade de manutenção*, pois algumas (mas nem todas) mudanças no arquivo principal podem ser refletidas apenas no índice principal, sem a necessidade de alterar os índices secundários.
- Índices *fortemente ligados* relacionam a chave secundária *diretamente ao registro* no arquivo principal. A busca nesse tipo de índice é *mais eficiente* do que a com índices fracamente ligados, pois é possível acessar o registro diretamente, sem fazer uma busca intermediária no índice principal. Entretanto, a complexidade de manutenção desse tipo de índice é maior se comparada à de índices fracamente ligados.

* Árvores B
* Hashing
* Compressão
