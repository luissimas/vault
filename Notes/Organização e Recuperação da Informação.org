#+title:Organização e Recuperação da Informação

Organização e Recuperação da Informação, como o nome já diz, é a área que estuda como organizar e recuperar informações armazenadas na memória secundária de sistemas computacionais.

* Processamento sequencial e ordenação externa
A ordenação externa consiste em classificar e ordenar por algum critério os registros armazenados em um arquivo. Naturalmente, o *acesso a disco* é algo muito mais *custoso* do que o acesso a dados na memória principal, portanto o principal objetivo dos algoritmos que lidam com processamento e ordenação de arquivos é fazer o mínimo de *acessos a disco possíveis*.

A primeira técnica usada para reduzir o número de acessos é o *acesso sequencial* aos registros. Quando o processamento de um arquivo é sequencial, isto é, os registros são acessados em ordem e em sequência, o tempo de acesso é otimizado, pois reduz-se o tempo gasto com o /seeking/ (movimento da cabeça de leitura do disco), já que a cabeça é posicionada apenas uma vez, e então os dados podem ser lidos com a rotação do disco, sem necessidade de um novo /seeking/.

Quando dois ou mais arquivos são processados ao mesmo tempo, cada um de forma sequencial, temos o chamado *processamento cossequencial*.

Nem sempre a ordenação externa é necessária, e em geral o melhor a se fazer é evitá-la, visto que é muito mais eficiente carregar todos os registros na memória principal, utilizar um algoritmo de ordenação, e então escrever os dados no arquivo. Entretanto, nem *sempre é possível carregar todos os dados na memória principal*, e é justamente nesses casos que a ordenação externa se faz necessária.

Visando a eficiência, um algoritmo de ordenação externa deve sempre buscar minimizar o número de acessos a disco, isso pode ser feito com duas ações principais:

- Ler cada registro o menor número de vezes possível.
- Processar o arquivo sequencialmente, do início ao fim.

** Ordenação por intercalação balanceada
O principal método de *ordenação externa* é a ordenação por intercalação balanceada, que utiliza tanto da memória principal quanto a secundária para ordenar os dados de um arquivo.

Esse algoritmo consiste em ler o arquivo sequencialmente, carregando o máximo de registros possíveis na memória, ordenando-os na memória principal e então escrevendo-os em arquivos intermediários, formando *blocos* de registros ordenados nos arquivos. Após isso, os arquivos intermediários são lidos cossequencialmente e é feito o *merge dos blocos* dos arquivos sucessivamente em mais arquivos intermediários, até que se obtenha um *único bloco ordenado* no arquivo final. Com esse método de leitura, é possível ler apenas um registro de cada bloco intermediário por vez, tornando o número de registros do arquivo inicial irrelevante para o processamento.

Dado um arquivo contento $n$ registros, e uma memória principal com capacidade para até $m$ registros. A passada inicial sobre o arquivo produz $\frac{n}{m}$ blocos ordenados. Seja $P$ uma função tal que $P(n)$ é o número de passadas para a fase de intercalação dos blocos ordenados, e seja $f$ o número de arquivos intermediários utilizados em cada passada, para uma intercalação com $f$ caminhos o número de passadas é dado por

$$ P(n) = \log_f \frac{n}{m}$$

Considerando a primeira passada pelo arquivo para formar os primeiros blocos ordenados, o número total de passadas pelo arquivo é dado por $P(n) + 1$.

* Armazenamento e organização de arquivos
Os dispositivos de armazenamento secundário são geralmente *dispositivos de blocos*, isto é, a unidade mínima de armazenamento não são bytes, e sim *grupos de bytes*.

Além da formatação /física do disco/ em setores, trilhas e cilindros, existe também uma /formatação lógica/, feita através de um *sistema de arquivos*. Um sistema de arquivos divide o disco em *regiões endereçáveis* para o sistema operacional e fornece a infraestrutura básica de manipulação de arquivos em memória secundária, oferecendo operações primitivas básicas para a manipulação desses arquivos.

No disco, um arquivo nada mais é do que uma *sequência de bytes* armazenados de forma contínua. Entretanto, para o sistema de arquivos um arquivo é na realidade um conjunto de *páginas de disco*. As páginas de disco são um *conjunto de setores* no disco, e são a unidade de transferência entre disco e memória principal pelo sistema operacional, ou seja, quando uma leitura ou escrita é solicitada ao sistema operacional, uma página inteira é lida ou escrita, independente do tamanho do arquivo de leitura ou da quantidade de dados a ser escrita. Além disso, o sistema operacional também fornece a abstração de *posição corrente*. A posição corrente no arquivo é uma abstração que permite especificar a partir de qual byte um arquivo deve ser lido ou escrito.

#+caption: Páginas de disco.
#+attr_org: :width 500
[[../Attachments/ORI/paginasdisco.png]]

O fato dos arquivos serem gravados ao longo de blocos de disco gera um efeito colateral: a *fragmentação interna*. A fragmentação ocorre quando um arquivo não usa seu último bloco completamente, desperdiçando o espaço do resto do bloco. Como os blocos são as unidades endereçáveis do disco, *um bloco deve conter apenas um arquivo*, portanto o espaço restante de um bloco que não está sendo completamente utilizado não pode ser reaproveitada para nenhum arquivo.

Um arquivo é apenas uma *sequência de bytes* escritos no disco, e uma sequência de bytes por si só *não tem valor ou informação alguma*, pois não há *contexto* e nem *estrutura* para que os dados armazenados tenham algum significado. Portanto, além de uma forma de armazenamento e endereçamento, é necessário estabelecer um método para *impor estrutura* aos dados armazenados, organizar os arquivos. A organização de arquivos é feita em um *nível conceitual* através de campos e registros.

** Campos
Os campos são a menor unidade lógica de armazenamento, geralmente utilizados para armazenar um *dado singular*. Cada campo ocupa um tamanho no arquivo final, e esse tamanho pode ser *fixo* ou *variável*.

Campos de *tamanho fixo* têm seu tamanho definido previamente, independente do dado a ser armazenado. Esse tipo de campo torna a *busca simples*, pois sabendo previamente o tamanho de todos os campos é fácil encontrar a posição deles nos arquivos. Entretanto, esse método pode gerar um grande *desperdício de armazenamento*, pois o espaço alocado nem sempre é usado por completo. Esse problema se agrava ainda mais quando os dados a serem armazenados têm uma alta variação de tamanho.

Para campos de *tamanho variável* existem algumas alternativas de implementação: O primeiro método de implementação consiste em *armazenar o tamanho* ocupado por cada campo *antes do campo* em si. Dessa forma, pode-se ler o tamanho do primeiro campo e então saber qual a posição do segundo, e assim sucessivamente. É possível também *separar os campos por delimitadores*, caracteres especiais que não fazem parte dos dados representados. Esses separadores são *inseridos ao final de cada campo*. Dessa forma, é possível saber onde um campo se inicia e termina com base nos delimitadores ao seu redor. Outra alternativa é o uso de *tags*, criando uma expressão de chave-valor no campo. Nessa forma de implementação uma *tag* é colocada *antes do campo*, *definindo a semântica* para o dado. Esse método geralmente é utilizado em conjunto com outros, como os delimitadores. Em geral, os campos de tamanho variável são mais *eficientes em termos de armazenamento*, porém *aumentam a complexidade das buscas* no arquivo.

** Registros
Os registros são agrupamentos de campos, que definem uma informação mais complexa com vários atributos, ou uma *entidade*. Da mesma forma que é necessário organizar os campos dentro de registros, é necessário organizar os registros dentro de arquivos. Existem várias maneiras de organizar os registros em um arquivo, sendo algumas delas análogas à organização de campos, mas com algumas peculiaridades.

A primeira alternativa é manter registros de *tamanho fixo*, isso pode ser atingido mantendo campos de tamanho fixo ou variável. Se os campos de um registro possuem tamanho fixo, então esse registro obrigatoriamente tem tamanho fixo. Entretanto, se um registro tem tamanho fixo, isso não implica nem em um número fixo de campos e nem em um tamanho fixo para esses campos.

É possível também manter registros de *tamanho variável* com um *número fixo de campos*. Isso cria a necessidade de utilização de algum método de separação dos campos, como delimitadores. Nesse tipo de implementação o tamanho do registro em bytes varia, mas como seu número de campos é sempre o mesmo, é possível distinguir os registros através dos campos.

Outra alternativa é utilizar um *indicador de tamanho* para os registros. Dessa forma, no início de cada registro há um indicador que fornece o tamanho do registro. Note que nessa implementação é necessário que os campos sejam separados internamente por delimitadores.

Existe ainda uma forma de manter registros de tamanho variável sem a necessidade de indicadores. Esse método consiste em manter um *índice de endereçamento* em um arquivo secundário, que armazena o endereço do primeiro byte de cada registro no arquivo principal. Dessa forma, é possível acessar cada registro utilizando os endereços e calcular seu tamanho a partir do próximo endereço. Note que essa implementação introduz a preocupação de manter consistência entre os dois arquivos, quaisquer modificações no arquivo principal devem ser refletidas no arquivo de índice.

É possível ainda *separar os registros com delimitadores*, de maneira análoga à separação de campos. Note que para combinar os delimitadores de campos e de registros esses delimitadores devem ser caracteres diferentes.

* Indexação
* Árvores B
* Hashing
* Compressão
